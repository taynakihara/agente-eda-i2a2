
from __future__ import annotations

import os
from io import StringIO
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt

# Opcional (usado apenas no heatmap). Se n√£o desejar a depend√™ncia, ver TODO abaixo
import seaborn as sns  # noqa: F401

try:
    from groq import Groq  # type: ignore
except Exception:
    Groq = None 

# =========================
# Configura√ß√µes e Constantes
# =========================

APP_TITLE = "ü§ñ Agente de An√°lise de Dados (CSV)"
APP_SUBTITLE = "Ferramenta inteligente para an√°lise de qualquer arquivo CSV com IA"
PAGE_CONFIG = dict(page_title="An√°lise de Dados CSV", page_icon="üìä", layout="wide")

# Limites de renderiza√ß√£o para n√£o travar a UI em datasets grandes
MAX_NUMERIC_HISTS = 12
MAX_CATEGORICAL_BARS = 6
MAX_BOX_PLOTS = 8

# Amostragem para opera√ß√µes pesadas
SAMPLE_FOR_PLOTS = 100_000  # se o dataset for maior, faz uma amostra para gr√°ficos
SAMPLE_FOR_STATS = 250_000  # amostra para estat√≠sticas e correla√ß√£o

DARK_BG = "#0E1117"


# =========================

st.markdown(
    """
    <h1 style='text-align: center; color: #00BFFF;'>
        ü§ñ Agente de An√°lise de Dados (CSV)
    </h1>
    <h3 style='text-align: center; color: #AAAAAA;'>
        Ferramenta inteligente para an√°lise de qualquer arquivo CSV com IA
    </h3>
    """,
    unsafe_allow_html=True
)


# CSS customizado
st.markdown(
    """
    <style>
    /* Layout padr√£o (antes do upload) ‚Üí centralizado */
    .block-container {
        max-width: 1100px;
        margin: auto;
    }

    /* Quando tiver tabelas/dataframes (ap√≥s upload) ‚Üí ocupa a tela toda */
    .stDataFrame, .stTable {
        max-width: 100% !important;
    }

    /* Ajusta responsividade das abas */
    div[data-baseweb="tab-list"] {
        display: flex;
        justify-content: space-around;
        flex-wrap: wrap;
    }

    /* Ajusta largura dos elementos grandes */
    .element-container {
        width: 100% !important;
    }
    </style>
    """,
    unsafe_allow_html=True
)



# =========================
# Fun√ß√µes utilit√°rias
# =========================

def _maybe_sample(df: pd.DataFrame, max_rows: int) -> pd.DataFrame:
    """Retorna amostra do DataFrame caso ele exceda max_rows (mantendo aleatoriedade)."""
    if len(df) > max_rows:
        return df.sample(n=max_rows, random_state=42)
    return df


@st.cache_data(show_spinner=False)
def load_csv(file) -> Tuple[pd.DataFrame, Optional[str]]:
    """
    L√™ CSV com detec√ß√£o de separador e fallback de encoding.
    Evita o problema de carregar tudo como uma coluna s√≥.
    """
    try:
        df = pd.read_csv(file, sep=None, engine="python", encoding="utf-8", low_memory=False)
        return df, None
    except Exception:
        try:
            file.seek(0)
            df = pd.read_csv(file, sep=None, engine="python", encoding="latin1", low_memory=False)
            return df, None
        except Exception as e2:
            return pd.DataFrame(), f"Erro ao carregar CSV: {e2}"




@st.cache_data(show_spinner=False)
def get_overview(data: pd.DataFrame) -> Dict[str, object]:
    """Retorna dicion√°rio com vis√£o geral e tabelas auxiliares."""
    memory_mb = data.memory_usage(deep=True).sum() / 1024 ** 2
    tipos_dados = pd.DataFrame({
        "Coluna": data.columns,
        "Tipo": data.dtypes.astype(str).values,
        "Valores √önicos": [data[c].nunique(dropna=True) for c in data.columns],
        "Valores Nulos": [int(data[c].isna().sum()) for c in data.columns],
        "% Nulos": [f"{(data[c].isna().mean() * 100):.1f}%" for c in data.columns],
    })

    desc = None
    numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
    if numeric_cols:
        # amostra para acelerar describe em datasets gigantes
        data_stats = _maybe_sample(data[numeric_cols], SAMPLE_FOR_STATS)
        desc = data_stats.describe()

    return {
        "shape": data.shape,
        "memory_mb": memory_mb,
        "tipos_dados": tipos_dados,
        "desc": desc,
        "numeric_cols": numeric_cols,
        "categorical_cols": data.select_dtypes(include=["object", "category"]).columns.tolist(),
    }


def _setup_dark_axes(ax):
    """Aplica tema dark consistente em cada eixo."""
    ax.set_facecolor(DARK_BG)
    ax.tick_params(colors="white", labelsize=8)
    ax.grid(True, alpha=0.3)


def _new_fig(size=(12, 6)):
    fig, ax = plt.subplots(figsize=size)
    fig.patch.set_facecolor(DARK_BG)
    return fig, ax


def _time_columns(data: pd.DataFrame) -> List[str]:
    """Detecta colunas temporais por nome e parse confi√°vel."""
    candidates = [c for c in data.columns if any(w in c.lower() for w in ("time", "date", "timestamp", "data", "dt_"))]
    parsed = []
    for c in candidates:
        try:
            pd.to_datetime(data[c], errors="raise")  # valida parse
            parsed.append(c)
        except Exception:
            # tenta parse brando
            if pd.to_datetime(data[c], errors="coerce").notna().any():
                parsed.append(c)
    return list(dict.fromkeys(parsed))


def _safe_corr(df: pd.DataFrame) -> pd.DataFrame:
    """Correla√ß√£o protegida contra constantes/NaN."""
    df2 = df.select_dtypes(include=[np.number]).copy()
    df2 = df2.loc[:, df2.nunique(dropna=True) > 1]  # remove colunas constantes
    if df2.empty or df2.shape[1] < 2:
        return pd.DataFrame()
    # amostra para acelerar
    df2 = _maybe_sample(df2, SAMPLE_FOR_STATS)
    return df2.corr(numeric_only=True)


def _top_frequencies(s: pd.Series, k: int = 10) -> pd.Series:
    """Top-k frequ√™ncias (com limpeza de NaN)."""
    return s.dropna().astype(str).value_counts().head(k)


# =========================
# Se√ß√µes de UI (tabs)
# =========================

def render_tab_overview(data: pd.DataFrame, overview: Dict[str, object]) -> None:
    st.header("üìã Vis√£o Geral dos Dados")
    c1, c2 = st.columns(2)

    with c1:
        st.subheader("Informa√ß√µes B√°sicas")
        st.write(f"**N√∫mero de linhas:** {overview['shape'][0]:,}")
        st.write(f"**N√∫mero de colunas:** {overview['shape'][1]:,}")
        st.write(f"**Tamanho em mem√≥ria:** {overview['memory_mb']:.2f} MB")

        st.subheader("Tipos de Dados")
        st.dataframe(overview["tipos_dados"], use_container_width=True)

    with c2:
        st.subheader("Primeiras 10 Linhas")
        st.dataframe(data.head(10), use_container_width=True)

        st.subheader("Estat√≠sticas Descritivas")
        if overview["desc"] is not None:
            st.dataframe(overview["desc"], use_container_width=True)
        else:
            st.info("N√£o h√° vari√°veis num√©ricas para descrever.")


def render_tab_distributions(data: pd.DataFrame, numeric_cols: List[str], categorical_cols: List[str]) -> None:
    st.header("üìä Distribui√ß√£o das Vari√°veis")

    # -------- Num√©ricas (uma de cada vez) --------
    if numeric_cols:
        st.subheader("Vari√°veis Num√©ricas")
        col_select_num = st.selectbox(
            "Selecione uma vari√°vel num√©rica:",
            numeric_cols,
            key="dist_num_select"  # chave √∫nica
        )
        with st.spinner(f"‚è≥ Gerando histograma de {col_select_num}..."):
            data_plot = _maybe_sample(data[[col_select_num]], SAMPLE_FOR_PLOTS)
            Q1, Q3 = data_plot[col_select_num].quantile([0.01, 0.99])
            filtered = data_plot[col_select_num].clip(lower=Q1, upper=Q3)

            fig, ax = _new_fig((10, 6))
            ax.hist(filtered.dropna(), bins=30, alpha=0.7, edgecolor="white")
            ax.set_title(f"Distribui√ß√£o: {col_select_num}", color="white", fontsize=14)
            _setup_dark_axes(ax)
            plt.tight_layout()
            st.pyplot(fig)
            plt.close()
    else:
        st.info("N√£o h√° vari√°veis num√©ricas no dataset.")

    # -------- Categ√≥ricas (uma de cada vez) --------
    if categorical_cols:
        st.subheader("Vari√°veis Categ√≥ricas")
        col_select_cat = st.selectbox(
            "Selecione uma vari√°vel categ√≥rica:",
            categorical_cols,
            key="dist_cat_select"  # chave √∫nica
        )

        with st.spinner(f"‚è≥ Gerando barras de {col_select_cat}..."):
            vc = _top_frequencies(data[col_select_cat])

            fig, ax = _new_fig((10, 6))
            bars = ax.bar(range(len(vc)), vc.values, alpha=0.85)
            ax.set_title(f"Distribui√ß√£o: {col_select_cat}", color="white", fontsize=14)
            ax.set_xticks(range(len(vc)))
            ax.set_xticklabels(vc.index, rotation=45, ha="right", color="white")
            _setup_dark_axes(ax)

            if len(vc) > 0:
                ymax = float(vc.values.max())
                for b, v in zip(bars, vc.values):
                    ax.text(b.get_x() + b.get_width() / 2.0, b.get_height() + 0.01 * ymax, f"{v:,}",
                            ha="center", va="bottom", color="white", fontsize=9)

            plt.tight_layout()
            st.pyplot(fig)
            plt.close()
    else:
        st.info("N√£o h√° vari√°veis categ√≥ricas no dataset.")


        # Categ√≥ricas
    if categorical_cols:
        st.subheader("Vari√°veis Categ√≥ricas")
        col_select_cat = st.selectbox("Selecione uma vari√°vel categ√≥rica:", categorical_cols)
        vc = _top_frequencies(data[col_select_cat])

        fig, ax = _new_fig((10, 6))
        bars = ax.bar(range(len(vc)), vc.values, alpha=0.85)
        ax.set_title(f"Distribui√ß√£o: {col_select_cat}", color="white", fontsize=14)
        ax.set_xticks(range(len(vc)))
        ax.set_xticklabels(vc.index, rotation=45, ha="right", color="white")
        _setup_dark_axes(ax)

        for b, v in zip(bars, vc.values):
            ax.text(
                b.get_x() + b.get_width() / 2.0,
                b.get_height() + 0.01 * vc.values.max(),
                f"{v:,}",
                ha="center", va="bottom", color="white", fontsize=9
            )

        plt.tight_layout()
        st.pyplot(fig)
        plt.close()




def render_tab_correlations(data: pd.DataFrame, numeric_cols: List[str]) -> None:
    st.header("üîç Correla√ß√µes entre Vari√°veis")

    if len(numeric_cols) < 2:
        st.info("√â necess√°rio ter pelo menos 2 vari√°veis num√©ricas para calcular correla√ß√µes.")
        return

    corr = _safe_corr(data[numeric_cols])
    if corr.empty:
        st.info("N√£o foram encontradas correla√ß√µes calcul√°veis (colunas constantes ou insuficientes).")
        return

    # Heatmap
    fig, ax = plt.subplots(figsize=(12, 10))
    fig.patch.set_facecolor(DARK_BG)

    # TODO: Se quiser remover seaborn da stack, substitua por pcolormesh do matplotlib.
    sns.heatmap(
        corr,
        annot=True,
        cmap="RdYlBu_r",
        center=0,
        square=True,
        fmt=".2f",
        cbar_kws={"shrink": 0.8},
        ax=ax,
    )
    ax.set_title("Matriz de Correla√ß√£o", color="white", fontsize=16, pad=20)
    ax.set_facecolor(DARK_BG)
    plt.xticks(rotation=45, ha="right", color="white")
    plt.yticks(rotation=0, color="white")
    plt.tight_layout()
    st.pyplot(fig)
    plt.close()

    # Top correla√ß√µes
    st.subheader("Correla√ß√µes Mais Significativas")
    pairs = []
    cols = corr.columns.tolist()
    for i in range(len(cols)):
        for j in range(i + 1, len(cols)):
            v = corr.iloc[i, j]
            if pd.notna(v) and abs(v) > 0.1:
                pairs.append({
                    "Vari√°vel 1": cols[i],
                    "Vari√°vel 2": cols[j],
                    "Correla√ß√£o": float(v),
                    "For√ßa": "Forte" if abs(v) > 0.7 else ("Moderada" if abs(v) > 0.3 else "Fraca")
                })
    if pairs:
        df_pairs = pd.DataFrame(pairs).sort_values("Correla√ß√£o", key=lambda s: s.abs(), ascending=False)
        st.dataframe(df_pairs, use_container_width=True)
    else:
        st.info("N√£o foram encontradas correla√ß√µes significativas.")


def render_tab_trends(data: pd.DataFrame, numeric_cols: List[str], categorical_cols: List[str]) -> None:
    st.header("üìà An√°lise de Tend√™ncias")

    # -------- Tend√™ncias Temporais --------
    tcols = _time_columns(data)
    if tcols:
        st.subheader("Tend√™ncias Temporais")

        time_col = st.selectbox(
            "Selecione a coluna temporal:",
            tcols,
            key="trend_time_select"  # chave √∫nica
        )

        numeric_choices = [c for c in numeric_cols if c != time_col]
        if not numeric_choices:
            st.info("N√£o h√° vari√°vel num√©rica dispon√≠vel diferente da coluna temporal selecionada.")
        else:
            numeric_col = st.selectbox(
                "Selecione a vari√°vel para an√°lise temporal:",
                numeric_choices,
                key="trend_num_select"  # chave √∫nica
            )

            d = data.loc[:, [time_col, numeric_col]].copy()

            # Garante Series mesmo se houver duplicata de nome
            time_obj = d[time_col]
            if isinstance(time_obj, pd.DataFrame):
                time_obj = time_obj.iloc[:, 0]

            # Converte tempo (num√©rico -> segundos desde base; string/datetime -> to_datetime)
            if pd.api.types.is_numeric_dtype(time_obj):
                base = pd.Timestamp("2000-01-01")
                d[time_col] = base + pd.to_timedelta(pd.to_numeric(time_obj, errors="coerce"), unit="s")
            else:
                d[time_col] = pd.to_datetime(time_obj, errors="coerce")

            d = d.dropna(subset=[time_col]).sort_values(time_col)
            d = _maybe_sample(d, SAMPLE_FOR_PLOTS)

            with st.spinner(f"‚è≥ Plotando s√©rie temporal de {numeric_col}..."):
                fig, ax = _new_fig((12, 6))
                ax.plot(d[time_col], d[numeric_col], alpha=0.8)
                ax.set_title(f"Tend√™ncia Temporal: {numeric_col}", color="white", fontsize=14)
                ax.set_xlabel("Tempo", color="white")
                ax.set_ylabel(numeric_col, color="white")
                _setup_dark_axes(ax)
                plt.tight_layout()
                st.pyplot(fig)
                plt.close()
    else:
        st.info("N√£o foram identificadas colunas temporais no dataset.")

    # -------- Padr√µes em Categ√≥ricas (com key √∫nica) --------
    if categorical_cols:
        st.subheader("Padr√µes em Vari√°veis Categ√≥ricas")
        cat_col = st.selectbox(
            "Selecione uma vari√°vel categ√≥rica:",
            categorical_cols,
            key="trend_cat_select"  # chave √∫nica (evita conflito com aba Distribui√ß√µes)
        )
        vc = data[cat_col].value_counts(dropna=True)
        c1, c2 = st.columns(2)
        with c1:
            st.write("**Valores Mais Frequentes:**")
            st.dataframe(vc.head(10).reset_index(names=[cat_col, "contagem"]), use_container_width=True)
        with c2:
            st.write("**Valores Menos Frequentes:**")
            st.dataframe(vc.tail(10).reset_index(names=[cat_col, "contagem"]), use_container_width=True)



    # Colunas temporais
    tcols = _time_columns(data)
    if tcols:
        st.subheader("Tend√™ncias Temporais")

        time_col = st.selectbox("Selecione a coluna temporal:", tcols)
        numeric_col = st.selectbox("Selecione a vari√°vel para an√°lise temporal:", numeric_cols) if numeric_cols else None

        if time_col and numeric_col:
            # Ordena e converte tempo de forma confi√°vel
            d = data[[time_col, numeric_col]].copy()
            d[time_col] = pd.to_datetime(d[time_col], errors="coerce")
            d = d.dropna(subset=[time_col])
            d = d.sort_values(time_col)

            # Amostra para gr√°fico
            d = _maybe_sample(d, SAMPLE_FOR_PLOTS)

            fig, ax = _new_fig((12, 6))
            ax.plot(d[time_col], d[numeric_col], alpha=0.8)
            ax.set_title(f"Tend√™ncia Temporal: {numeric_col}", color="white", fontsize=14)
            ax.set_xlabel("Tempo", color="white")
            ax.set_ylabel(numeric_col, color="white")
            _setup_dark_axes(ax)
            plt.tight_layout()
            st.pyplot(fig)
            plt.close()
    else:
        st.info("N√£o foram identificadas colunas temporais no dataset.")

    # Padr√µes categ√≥ricos
    if categorical_cols:
        st.subheader("Padr√µes em Vari√°veis Categ√≥ricas")
        cat_col = st.selectbox("Selecione uma vari√°vel categ√≥rica:", categorical_cols)
        if cat_col:
            vc = data[cat_col].value_counts(dropna=True)
            c1, c2 = st.columns(2)
            with c1:
                st.write("**Valores Mais Frequentes:**")
                st.dataframe(vc.head(10).reset_index(names=[cat_col, "contagem"]), use_container_width=True)
            with c2:
                st.write("**Valores Menos Frequentes:**")
                st.dataframe(vc.tail(10).reset_index(names=[cat_col, "contagem"]), use_container_width=True)


def render_tab_outliers(data: pd.DataFrame, numeric_cols: List[str]) -> None:
    st.header("‚ö†Ô∏è Detec√ß√£o de Anomalias")

    if not numeric_cols:
        st.info("N√£o h√° vari√°veis num√©ricas para an√°lise de outliers.")
        return

    st.subheader("Outliers por Vari√°vel")

    # Amostra para IQR em datasets muito grandes
    d = _maybe_sample(data[numeric_cols], SAMPLE_FOR_STATS)

    summary = []
    for col in numeric_cols:
        s = d[col].dropna()
        if s.empty:
            continue
        Q1, Q3 = s.quantile([0.25, 0.75])
        IQR = Q3 - Q1
        lower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR
        mask = (s < lower) | (s > upper)
        count = int(mask.sum())
        pct = (count / len(s)) * 100

        summary.append({
            "Vari√°vel": col,
            "Total de Outliers": count,
            "Percentual": f"{pct:.2f}%",
            "Limite Inferior": f"{lower:.2f}",
            "Limite Superior": f"{upper:.2f}",
            "Valor M√≠nimo": f"{s.min():.2f}",
            "Valor M√°ximo": f"{s.max():.2f}",
        })

    st.dataframe(pd.DataFrame(summary), use_container_width=True)

    # Boxplots
    st.subheader("Visualiza√ß√£o de Outliers (Boxplots)")
    cols_to_plot = numeric_cols[:MAX_BOX_PLOTS]
    cols_per_row = 4
    rows = (len(cols_to_plot) + cols_per_row - 1) // cols_per_row
    fig, axes = plt.subplots(rows, cols_per_row, figsize=(16, 4 * rows))
    fig.patch.set_facecolor(DARK_BG)
    if rows == 1:
        axes = axes.reshape(1, -1) if len(cols_to_plot) > 1 else [axes]

    for i, col in enumerate(cols_to_plot):
        r, c = i // cols_per_row, i % cols_per_row
        ax = axes[r][c] if rows > 1 else axes[c]
        bp = ax.boxplot(d[col].dropna(), patch_artist=True)
        bp["boxes"][0].set_alpha(0.7)
        _setup_dark_axes(ax)
        ax.set_title(col, color="white", fontsize=10)

    for i in range(len(cols_to_plot), rows * cols_per_row):
        r, c = i // cols_per_row, i % cols_per_row
        if rows > 1:
            fig.delaxes(axes[r][c])
        else:
            fig.delaxes(axes[c])

    plt.tight_layout()
    st.pyplot(fig)
    plt.close()


def render_tab_ai(data: pd.DataFrame, overview: Dict[str, object]) -> None:
    st.header("ü§ñ Consulta Inteligente com IA Groq")
    st.markdown("Fa√ßa perguntas sobre seus dados e obtenha insights com modelos avan√ßados.")

    # Chave da API
    c1, c2 = st.columns([2, 1])
    with c1:
        # Prioriza st.secrets se existir (mais seguro)
        default_key = st.secrets.get("GROQ_API_KEY", "") if hasattr(st, "secrets") else ""
        api_key = st.text_input("üîë Insira sua chave da API da Groq:", type="password", value=default_key,
                                help="Use st.secrets['GROQ_API_KEY'] para evitar digitar toda vez.")
    with c2:
        model_options = {
            "llama-3.3-70b-versatile": "ü¶ô Llama 3.3 70B (Recomendado)",
            "llama-3.1-8b-instant": "ü¶ô Llama 3.1 8B (R√°pido)",
            "openai/gpt-oss-120b": "üß† GPT OSS 120B (Poderoso)",
            "openai/gpt-oss-20b": "üß† GPT OSS 20B (Eficiente)",
        }
        selected_model = st.selectbox(
            "üß† Escolha o modelo:",
            options=list(model_options.keys()),
            format_func=lambda x: model_options[x],
            index=0,
        )

    if not api_key:
        st.info("üîë Insira sua chave da API da Groq para usar a consulta inteligente.")
        st.markdown(
            """
            **Como obter sua chave da API:**
            1. console.groq.com ‚Üí API Keys ‚Üí New key
            2. Copie e cole acima

            **Boas pr√°ticas:** use `st.secrets` para n√£o digitar a chave sempre e evitar expor em reposit√≥rios.
            """
        )
        return

    if Groq is None:
        st.error("Biblioteca `groq` n√£o instalada. Rode `pip install groq`.")
        return

    # Contexto ‚Äúcompacto‚Äù (evita enviar dados linha a linha)
    numeric_cols: List[str] = overview["numeric_cols"]  # type: ignore
    context_summary = {
        "num_linhas": int(overview["shape"][0]),      # type: ignore
        "num_colunas": int(overview["shape"][1]),     # type: ignore
        "colunas": list(map(str, data.columns.tolist())),
        "tipos": {c: str(t) for c, t in data.dtypes.items()},
        "nulos": {c: int(data[c].isna().sum()) for c in data.columns},
        "unicos": {c: int(data[c].nunique(dropna=True)) for c in data.columns},
        "describe": overview["desc"].to_dict() if overview["desc"] is not None else "sem_numericas",
    }

    question = st.text_area(
        "üí≠ Sua pergunta sobre os dados:",
        placeholder="Ex.: Quais vari√°veis mais se correlacionam? H√° ind√≠cios de sazonalidade?",
        height=100,
    )

    with st.expander("‚öôÔ∏è Configura√ß√µes Avan√ßadas"):
        c1, c2 = st.columns(2)
        with c1:
            max_tokens = st.slider("M√°ximo de tokens:", 100, 2000, 1000)
            temperature = st.slider("Criatividade (temperature):", 0.0, 1.0, 0.7, 0.1)
        with c2:
            system_prompt = st.text_area(
                "Prompt do sistema (opcional):",
                value="Voc√™ √© um(a) especialista em an√°lise de dados e ci√™ncia de dados.",
                height=100,
            )

    if st.button("üöÄ Analisar com IA", type="primary"):
        if not question.strip():
            st.warning("‚ö†Ô∏è Digite uma pergunta antes de analisar.")
            return

        with st.spinner(f"ü§ñ Analisando com {model_options[selected_model]}..."):
            try:
                client = Groq(api_key=api_key)
                prompt = (
                    "Analise o dataset a partir do resumo e responda as pergunta com clareza,"
                    "Interaja com o usu√°rio de forma objetiva e sucinta,"
                    "Responda de forma independente, e aja com intelig√™ncia,"
                    "Fale somente baseado em dados e estat√≠sticas, sem sair do contexto do dataset,"
                    "citando poss√≠veis limita√ß√µes dos dados quando pertinente.\n\n"
                    f"RESUMO DO DATASET (compacto):\n{context_summary}\n\n"
                    f"PERGUNTA DO USU√ÅRIO: {question}\n"
                    "Sugira an√°lises complementares se fizer sentido."
                )

                response = client.chat.completions.create(
                    model=selected_model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": prompt},
                    ],
                    max_tokens=max_tokens,
                    temperature=temperature,
                )

                st.success("‚úÖ An√°lise conclu√≠da!")
                st.markdown("### üéØ Resposta da IA:")
                st.markdown(response.choices[0].message.content)

                if hasattr(response, "usage"):
                    with st.expander("üìä Informa√ß√µes de Uso"):
                        st.write(f"**Tokens usados:** {getattr(response.usage, 'total_tokens', 'N/D')}")
                        st.write(f"**Modelo:** {selected_model}")

            except Exception as e:
                st.error(f"‚ùå Erro ao consultar a API da Groq: {e}")
                st.info("Verifique a chave e a disponibilidade da API.")


# =========================
# Main (layout e fluxo)
# =========================

uploaded = st.file_uploader(
    "Carregue seu arquivo CSV para an√°lise",
    type=["csv"],
    help="Selecione um arquivo CSV para an√°lise explorat√≥ria",
)

# CSS condicional
if uploaded is None:
    # Antes do upload ‚Üí centralizado
    st.markdown(
        """
        <style>
        .block-container {
            max-width: 1000px;
            margin: auto;
            text-align: center;
        }
        </style>
        """,
        unsafe_allow_html=True
    )
else:
    # Depois do upload ‚Üí full width responsivo
    st.markdown(
        """
        <style>
        .block-container {
            max-width: 100% !important;
            padding-left: 2rem;
            padding-right: 2rem;
        }
        .stDataFrame, .stTable {
            max-width: 100% !important;
        }
        div[data-baseweb="tab-list"] {
            display: flex;
            justify-content: space-around;
            flex-wrap: wrap;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

if uploaded is not None:
    with st.spinner("‚è≥ Carregando arquivo CSV..."):
        data, err = load_csv(uploaded)

    if err:
        st.error(f"‚ùå {err}")
        st.info("Verifique se o arquivo est√° √≠ntegro, separador e encoding corretos.")
    elif data.empty:
        st.warning("Arquivo vazio ou sem colunas leg√≠veis.")
    else:
        st.success(f"‚úÖ Arquivo carregado! {data.shape[0]:,} linhas x {data.shape[1]:,} colunas.")
        overview = get_overview(data)

        tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(
            ["üìã Vis√£o Geral", "üìä Distribui√ß√µes", "üîç Correla√ß√µes", "üìà Tend√™ncias", "‚ö†Ô∏è Anomalias", "ü§ñ Consulta IA"]
        )

        with tab1:
            render_tab_overview(data, overview)
        with tab2:
            render_tab_distributions(data, overview["numeric_cols"], overview["categorical_cols"])  # type: ignore
        with tab3:
            render_tab_correlations(data, overview["numeric_cols"])  # type: ignore
        with tab4:
            render_tab_trends(data, overview["numeric_cols"], overview["categorical_cols"])  # type: ignore
        with tab5:
            render_tab_outliers(data, overview["numeric_cols"])  # type: ignore
        with tab6:
            render_tab_ai(data, overview)

else:
    st.markdown(
        """
        ## Bem-vindo ao Agente de An√°lise de Dados com IA!
        Carregue um CSV e explore as abas de an√°lise. Use a IA para perguntas espec√≠ficas sobre o dataset.
        """
    )


